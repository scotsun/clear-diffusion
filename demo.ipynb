{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import mlflow\n",
    "from mlflow.types import Schema, TensorSpec\n",
    "from mlflow.models import ModelSignature\n",
    "\n",
    "from sd_vae.ae import VAE\n",
    "from trainers import EarlyStopping\n",
    "from trainers.first_stage_trainer import CLEAR_VAEFirstStageTrainer\n",
    "\n",
    "from modules.loss import SupCon\n",
    "\n",
    "import data_utils.styled_mnist.corruptions as corruptions\n",
    "from data_utils.styled_mnist.data_utils import StyledMNISTGenerator, StyledMNIST\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST(\"./data\", train=True, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa052a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = StyledMNISTGenerator(\n",
    "    mnist,\n",
    "    {\n",
    "        corruptions.identity: 0.1,\n",
    "        corruptions.stripe: 0.15,\n",
    "        corruptions.zigzag: 0.25,\n",
    "        corruptions.canny_edges: 0.15,\n",
    "        lambda x: corruptions.scale(x, 5): 0.15,\n",
    "        corruptions.brightness: 0.2\n",
    "    },\n",
    ")\n",
    "dataset = StyledMNIST(\n",
    "    generator, \n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        lambda img: img / 255.0,\n",
    "    ])\n",
    ")\n",
    "\n",
    "train, test, valid = random_split(dataset, [40000, 10000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f2955",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=512, shuffle=True)\n",
    "valid_loader = DataLoader(valid, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8bafd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"lr\": 5e-4,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"batch_size\": 512,\n",
    "    \"beta\": 1/8,\n",
    "    \"gamma\": 100,\n",
    "}\n",
    "\n",
    "input_schema = Schema([TensorSpec(np.dtype(np.float32), [-1, 1, 32, 32])])\n",
    "output_schema = Schema([TensorSpec(np.dtype(np.float32), [-1, 1, 32, 32])])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "vae = VAE(\n",
    "    channels=32,\n",
    "    channel_multipliers=[1, 2, 4],\n",
    "    n_resnet_blocks=1,\n",
    "    x_channels=1,\n",
    "    z_channels=8,\n",
    "    norm_channels=32,\n",
    "    n_heads=4,\n",
    ").cuda()\n",
    "\n",
    "trainer = CLEAR_VAEFirstStageTrainer(\n",
    "    contrastive_criterion=SupCon(temperature=0.2),\n",
    "    model=vae,\n",
    "    early_stopping=EarlyStopping(patience=8),\n",
    "    verbose_period=2,\n",
    "    device=\"cuda\",\n",
    "    model_signature=signature,\n",
    "    args={\"beta\": params[\"beta\"], \"gamma\": params[\"gamma\"], \"vae_lr\": params[\"lr\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "mlflow.set_experiment(\"test\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    trainer.fit(epochs=51, train_loader=train_loader, valid_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(test_loader))['image'].to(\"cuda\")\n",
    "plt.imshow(make_grid(x, nrow=16).cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc74ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(test_loader))['image'].to(\"cuda\")\n",
    "best_model = mlflow.pytorch.load_model('runs:/a92347e169054c17924cc0da1fde2106/best_model')\n",
    "with torch.no_grad():\n",
    "    best_model.eval()\n",
    "    xhat, posterior = best_model(x)\n",
    "    plt.imshow(make_grid(xhat, nrow=16).cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d7cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = posterior.mu\n",
    "print(mu.shape)\n",
    "for i in range(mu.shape[1]):\n",
    "    plt.imshow(make_grid(mu[:,i][:,None,:,:], nrow=16).cpu().permute(1,2,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64767b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_c, z_s = mu.chunk(2, dim=1)\n",
    "z_s = torch.cat([z_s[2:], z_s[:2]], dim=0)\n",
    "z = torch.cat([z_c, z_s], dim=1).contiguous()\n",
    "z.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    best_model.eval()\n",
    "    z = z * 0.18215\n",
    "    x = best_model.decoder(z)\n",
    "    plt.imshow(make_grid(x, nrow=16).cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fa530",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 64, 10, 10) \n",
    "\n",
    "# Create a Global Average Pooling layer\n",
    "# output_size=1 means that the output of the pooling operation\n",
    "# will be 1x1 for each channel, effectively averaging over the entire spatial dimension.\n",
    "gap_layer = torch.nn.AdaptiveAvgPool2d(output_size=1)\n",
    "\n",
    "# Apply the GAP layer\n",
    "gap_layer(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f86996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
