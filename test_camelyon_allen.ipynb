{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from mlflow.types import Schema, TensorSpec\n",
    "from mlflow.models import ModelSignature\n",
    "\n",
    "from src.sd_vae.ae import VAE\n",
    "from src.trainers import EarlyStopping\n",
    "from src.trainers.first_stage_trainer import CLEAR_VAEFirstStageTrainer\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "from src.utils.exp_utils.train_utils import (\n",
    "    load_cfg,\n",
    "    build_first_stage_trainer,\n",
    "    xavier_init,\n",
    ")\n",
    "from src.utils.exp_utils.visual import feature_swapping_plot\n",
    "from src.utils.data_utils.camelyon import build_dataloader\n",
    "\n",
    "# in distribution swapping & ood x in distribution swapping \n",
    "\n",
    "\n",
    "# experiment protocal in-the-middle 要好好写\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = build_dataloader(\n",
    "    data_root=\"/hpc/group/engelhardlab/ms1008/image_data\",\n",
    "    batch_size=64,\n",
    "    download=False,\n",
    "    num_workers=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataloaders[\"train\"]\n",
    "base_train_loader = dataloaders[\"train\"]\n",
    "collate_fn = getattr(train_loader, \"collate_fn\", None)\n",
    "valid_loader = dataloaders['valid']\n",
    "test_loader = dataloaders['test']\n",
    "train_dataset = dataloaders[\"train\"].dataset\n",
    "n_total = len(train_dataset)\n",
    "n_train = int(0.6 * n_total)\n",
    "n_cv = n_total - n_train\n",
    "\n",
    "train_subset, cv_subset = random_split(\n",
    "    train_dataset,\n",
    "    [n_train, n_cv],\n",
    "    generator=torch.Generator().manual_seed(42)  \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=base_train_loader.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=base_train_loader.num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,  \n",
    ")\n",
    "\n",
    "cv_loader = DataLoader(\n",
    "    cv_subset,\n",
    "    batch_size=base_train_loader.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=base_train_loader.num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_cfg('./config/camelyon.yaml')\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = Schema([TensorSpec(np.dtype(np.float32), [-1, 1, 32, 32])])\n",
    "output_schema = Schema([TensorSpec(np.dtype(np.float32), [-1, 1, 32, 32])])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "vae = VAE(**cfg['vae']).to(device)\n",
    "\n",
    "vae.apply(xavier_init)\n",
    "\n",
    "trainer = CLEAR_VAEFirstStageTrainer(\n",
    "    model=vae,\n",
    "    early_stopping=EarlyStopping(patience=8),\n",
    "    verbose_period=2,\n",
    "    device=device,\n",
    "    model_signature=signature,\n",
    "    args=cfg[\"trainer_param\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "mlflow.set_experiment(\"test-camelyon\")\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_params(cfg['vae'] | cfg['trainer_param'])\n",
    "    trainer.fit(epochs=cfg['train']['epochs'], train_loader=train_loader, valid_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = run.info.run_id\n",
    "print(run_id)\n",
    "# run_id = '8a30d6b78488426bab8b7b09b014b80c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b231b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))[\"image\"].to(device)\n",
    "best_model = mlflow.pytorch.load_model(f\"runs:/{run_id}/best_model\")\n",
    "with torch.no_grad():\n",
    "    best_model.eval()\n",
    "    _, posterior = best_model(x)\n",
    "z_c, z_s = posterior.mu.split_with_sizes(\n",
    "    cfg[\"trainer_param\"][\"channel_split\"], dim=1\n",
    ")\n",
    "select = torch.randint(0, 32, (10,)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac7aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6000 1500 0.05 4 8 8a30d6b78488426bab8b7b09b014b80c\n",
    "\n",
    "feature_swapping_plot(\n",
    "    z_c[select],\n",
    "    z_s[select],\n",
    "    x[select],\n",
    "    best_model,\n",
    "    img_size=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from src.utils.exp_utils.visual import make_colored_grid\n",
    "\n",
    "def feature_swapping_plot_rows_cols(\n",
    "    z_c_rows,          \n",
    "    z_s_cols,         \n",
    "    x_rows,            \n",
    "    x_cols,            \n",
    "    vae: torch.nn.Module,\n",
    "    img_size=32,\n",
    "    out_dir=None,\n",
    "    run_id=None,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        n_row = z_c_rows.size(0)\n",
    "        n_col = z_s_cols.size(0)\n",
    "        device = z_c_rows.device\n",
    "\n",
    "        # Combine latent vectors\n",
    "        paired_z = torch.cat(\n",
    "            (\n",
    "                z_c_rows[:, None, :, :, :].repeat(1, n_col, 1, 1, 1),\n",
    "                z_s_cols[None, :, :, :, :].repeat(n_row, 1, 1, 1, 1),\n",
    "            ),\n",
    "            dim=2,\n",
    "        ).flatten(start_dim=0, end_dim=1)\n",
    "\n",
    "        # Decode\n",
    "        paired_z = paired_z * 0.18215\n",
    "        x_inter = vae.decoder(paired_z)\n",
    "        \n",
    "        maingrid = make_grid(x_inter, nrow=n_col, padding=2)\n",
    "\n",
    "  \n",
    "        top_bar = make_colored_grid(x_cols, nrow=n_col, color=\"red\")\n",
    "        left_bar = make_colored_grid(x_rows, nrow=1, color=\"blue\")\n",
    " \n",
    "        corner_h = top_bar.size(1)\n",
    "        corner_w = left_bar.size(2)\n",
    "        empty_corner = torch.ones(3, corner_h, corner_w).to(device)\n",
    "\n",
    "        top_row = torch.cat([empty_corner, top_bar], dim=2)\n",
    "        bottom_row = torch.cat([left_bar, maingrid], dim=2)\n",
    "        final_grid = torch.cat([top_row, bottom_row], dim=1)\n",
    "\n",
    "        plt.figure(figsize=(12, 12))  \n",
    "        plt.imshow(final_grid.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        if out_dir is not None:\n",
    "            out_dir = os.path.join(out_dir, run_id)\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            filepath = os.path.join(out_dir, \"swap_rows_cv_cols_train.png\")\n",
    "            plt.savefig(filepath, bbox_inches=\"tight\", pad_inches=0)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f49869",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test = next(iter(test_loader))\n",
    "x_test = batch_test[\"image\"].to(device)\n",
    "\n",
    "batch_cv = next(iter(cv_loader))\n",
    "x_cv = batch_cv[\"image\"].to(device)\n",
    "\n",
    "best_model = mlflow.pytorch.load_model(f\"runs:/{run_id}/best_model\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    best_model.eval()\n",
    "\n",
    "    _, posterior_test = best_model(x_test)\n",
    "    zc_test, zs_test = posterior_test.mu.split_with_sizes(\n",
    "        cfg[\"trainer_param\"][\"channel_split\"], dim=1\n",
    "    )\n",
    "\n",
    "    _, posterior_cv = best_model(x_cv)\n",
    "    zc_cv, zs_cv = posterior_cv.mu.split_with_sizes(\n",
    "        cfg[\"trainer_param\"][\"channel_split\"], dim=1\n",
    "    )\n",
    "\n",
    "n_row = 20   #\n",
    "n_col = 20  \n",
    "\n",
    "row_idx = torch.randint(0, x_test.size(0), (n_row,), device=device)\n",
    "col_idx = torch.randint(0, x_cv.size(0), (n_col,), device=device)\n",
    "\n",
    "feature_swapping_plot_rows_cols(\n",
    "    z_c_rows=zc_test[row_idx],   \n",
    "    z_s_cols=zs_cv[col_idx],   \n",
    "    x_rows=x_test[row_idx],     \n",
    "    x_cols=x_cv[col_idx],        \n",
    "    vae=best_model,\n",
    "    img_size=96,\n",
    "    out_dir=None,\n",
    "    run_id=run_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from src.modules.distribution import IsotropicNormalDistribution \n",
    "\n",
    "class DownstreamMLPTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        vae: nn.Module,\n",
    "        model: nn.Module,\n",
    "        optimizer: Optimizer,\n",
    "        criterion: nn.Module,\n",
    "        verbose_period: int,\n",
    "        device: torch.device,\n",
    "        transform=None,\n",
    "    ) -> None:\n",
    "        self.vae = vae\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.verbose_period = verbose_period\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "\n",
    "    def _unpack_batch(self, batch):\n",
    "        if isinstance(batch, dict):\n",
    "            if \"x\" in batch: x = batch[\"x\"]\n",
    "            elif \"image\" in batch: x = batch[\"image\"]\n",
    "            elif \"data\" in batch: x = batch[\"data\"]\n",
    "            else: x = list(batch.values())[0]\n",
    "\n",
    "            if \"y\" in batch: y = batch[\"y\"]\n",
    "            elif \"label\" in batch: y = batch[\"label\"]\n",
    "            elif \"target\" in batch: y = batch[\"target\"]\n",
    "            else: y = list(batch.values())[1]\n",
    "            \n",
    "        elif isinstance(batch, (list, tuple)):\n",
    "            x, y = batch[0], batch[1]\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported batch type: {type(batch)}\")\n",
    "            \n",
    "        return x, y\n",
    "\n",
    "    def _get_vae_feature(self, x):\n",
    "        moments = self.vae.encoder(x)\n",
    "        \n",
    "        posterior = IsotropicNormalDistribution(moments)\n",
    "\n",
    "        if hasattr(posterior, 'mean'):\n",
    "            z = posterior.mean\n",
    "        elif hasattr(posterior, 'mode'):\n",
    "            z = posterior.mode()\n",
    "        else:\n",
    "            c = moments.shape[1] // 2\n",
    "            z = moments[:, :c, :, :] \n",
    "\n",
    "        z = z.reshape(z.shape[0], -1) \n",
    "        \n",
    "        return z\n",
    "\n",
    "    def fit(self, epochs: int, train_loader: DataLoader, valid_loader: DataLoader = None):\n",
    "        for epoch in range(epochs):\n",
    "            self._train(train_loader, verbose=True, epoch_id=epoch)\n",
    "            if valid_loader:\n",
    "                self._valid(valid_loader, verbose=True, epoch_id=epoch)\n",
    "\n",
    "    def _train(self, dataloader: DataLoader, verbose: bool, epoch_id: int):\n",
    "        self.model.train()\n",
    "        \n",
    "        with tqdm(dataloader, unit=\"batch\", disable=not verbose) as bar:\n",
    "            bar.set_description(f\"epoch {epoch_id}\")\n",
    "            for batch in bar:\n",
    "                X_batch, y_batch = self._unpack_batch(batch)\n",
    "                \n",
    "                y_batch = y_batch.reshape(-1).long()\n",
    "                X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "                \n",
    "                if self.transform:\n",
    "                    X_batch = self.transform(X_batch)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    z_feature = self._get_vae_feature(X_batch)\n",
    "                \n",
    "                logits = self.model(z_feature)\n",
    "\n",
    "                loss = self.criterion(logits, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                bar.set_postfix(loss=float(loss))\n",
    "\n",
    "    def _valid(self, dataloader: DataLoader, verbose: bool, epoch_id: int):\n",
    "        if verbose:\n",
    "            (aupr_scores, auroc_scores), acc = self.evaluate(\n",
    "                dataloader, verbose, epoch_id\n",
    "            )\n",
    "            print(f\"val_acc: {acc:.3f}\")\n",
    "\n",
    "    def evaluate(self, dataloader: DataLoader, verbose: bool, epoch_id: int):\n",
    "        self.model.eval()\n",
    "        all_y = []\n",
    "        all_probs = []\n",
    "        groups = [] \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            iterator = tqdm(dataloader, disable=not verbose, desc=f\"val-epoch {epoch_id}\")\n",
    "            for batch in iterator:\n",
    "                X_batch, y_batch = self._unpack_batch(batch)\n",
    "                \n",
    "                g_batch = None\n",
    "                if isinstance(batch, dict):\n",
    "                    if \"c\" in batch: g_batch = batch[\"c\"]\n",
    "                    elif \"group\" in batch: g_batch = batch[\"group\"]\n",
    "                elif isinstance(batch, (list, tuple)) and len(batch) > 2:\n",
    "                    g_batch = batch[2]\n",
    "                if g_batch is not None:\n",
    "                    groups.append(g_batch.cpu().numpy())\n",
    "\n",
    "                y_batch = y_batch.reshape(-1)\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                \n",
    "                z_feature = self._get_vae_feature(X_batch)\n",
    "                \n",
    "                logits = self.model(z_feature)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "                all_y.append(y_batch.cpu())\n",
    "                all_probs.append(probs.cpu())\n",
    "\n",
    "        all_y = torch.cat(all_y).numpy()\n",
    "        all_probs = torch.cat(all_probs).numpy()\n",
    "        \n",
    "        if len(groups) > 0:\n",
    "            groups = np.concatenate(groups)\n",
    "        else:\n",
    "            groups = np.zeros_like(all_y)\n",
    "\n",
    "        acc = accuracy_score(all_y, np.argmax(all_probs, axis=1))\n",
    "        aupr_scores = {}\n",
    "        auroc_scores = {}\n",
    "        \n",
    "        unique_groups = np.unique(groups)\n",
    "        for g in unique_groups:\n",
    "            mask = (groups == g)\n",
    "            y_sub = all_y[mask]\n",
    "            prob_sub = all_probs[mask]\n",
    "            \n",
    "            if len(np.unique(y_sub)) > 1 and prob_sub.shape[1] >= 2:\n",
    "                try:\n",
    "                    auroc = roc_auc_score(y_sub, prob_sub[:, 1])\n",
    "                    aupr = average_precision_score(y_sub, prob_sub[:, 1])\n",
    "                except:\n",
    "                    auroc, aupr = 0.5, 0.0\n",
    "            else:\n",
    "                auroc, aupr = 0.5, 0.0\n",
    "            \n",
    "            k = f\"group_{g}\" if isinstance(g, (int, np.integer)) else str(g)\n",
    "            auroc_scores[k] = float(auroc)\n",
    "            aupr_scores[k] = float(aupr)\n",
    "            \n",
    "        return (aupr_scores, auroc_scores), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d251bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import mlflow.pytorch\n",
    "from src.modules.distribution import IsotropicNormalDistribution\n",
    "\n",
    "def evaluate_loaded_vae(best_model, train_loader, valid_loader, test_loader, device, n_class=2):\n",
    "\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "\n",
    "    for p in best_model.parameters():\n",
    "        p.requires_grad = False\n",
    "    print(\"Calculating MLP input dimension...\")\n",
    "    \n",
    "    try:\n",
    "        batch = next(iter(train_loader))\n",
    "        \n",
    "        if isinstance(batch, dict):\n",
    "            if \"x\" in batch: x_dummy = batch[\"x\"]\n",
    "            elif \"image\" in batch: x_dummy = batch[\"image\"]\n",
    "            elif \"data\" in batch: x_dummy = batch[\"data\"]\n",
    "            else: x_dummy = list(batch.values())[0]\n",
    "        else:\n",
    "            x_dummy = batch[0]\n",
    "            \n",
    "        x_dummy = x_dummy[0:1].to(device)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting dummy input: {e}. Fallback to random input (3x96x96).\")\n",
    "        x_dummy = torch.randn(1, 3, 96, 96).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        moments = best_model.encoder(x_dummy)\n",
    "\n",
    "        c = moments.shape[1] // 2\n",
    "        h, w = moments.shape[2], moments.shape[3]\n",
    "        \n",
    "        flatten_dim = c * h * w\n",
    "        \n",
    "    print(f\"Detected encoder output shape: {moments.shape}\")\n",
    "    print(f\"MLP input dimension (flattened): {flatten_dim}\")\n",
    "\n",
    "    mlp = nn.Sequential(\n",
    "        nn.Linear(flatten_dim, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, n_class), \n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(mlp.parameters(), lr=3e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    trainer = DownstreamMLPTrainer(\n",
    "        best_model, mlp, optimizer, criterion, 1, device\n",
    "    )\n",
    "\n",
    "    print(\"Training downstream MLP classifier...\")\n",
    "    trainer.fit(1, train_loader, valid_loader)\n",
    "\n",
    "    print(\"Evaluating on test set...\")\n",
    "    (aupr_scores, auroc_scores), acc = trainer.evaluate(test_loader, False, 0)\n",
    "\n",
    "    results = {\n",
    "        \"acc\": round(float(acc), 3),\n",
    "        \"pr\": {\n",
    "            \"overall\": round(np.mean(list(aupr_scores.values())), 3),\n",
    "            \"stratified\": aupr_scores,\n",
    "        },\n",
    "        \"roc\": {\n",
    "            \"overall\": round(np.mean(list(auroc_scores.values())), 3),\n",
    "            \"stratified\": auroc_scores,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "metrics = evaluate_loaded_vae(best_model, train_loader, valid_loader, test_loader, device, n_class=2) \n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "mu = posterior.mu\n",
    "print(mu.shape)\n",
    "for i in range(mu.shape[1]):\n",
    "    plt.imshow(make_grid(mu[:,i][:,None,:,:], nrow=16).cpu().permute(1,2,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77179c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cs = []\n",
    "z_ss = []\n",
    "labels = []\n",
    "styles = []\n",
    "channel_split = [4,8]\n",
    "with torch.no_grad():\n",
    "    best_model.eval()\n",
    "    for batch in tqdm(test_loader):\n",
    "        x = batch['image'].to(device)\n",
    "        _, posterior = best_model(x)\n",
    "        z_c, z_s = posterior.sample().split_with_sizes(channel_split, dim=1)\n",
    "        z_cs.append(z_c.cpu())\n",
    "        z_ss.append(z_s.cpu())\n",
    "        labels.append(batch['label'])\n",
    "        styles.append(batch['style'])\n",
    "\n",
    "z_cs = torch.cat(z_cs, dim=0)\n",
    "z_ss = torch.cat(z_ss, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "styles = torch.cat(styles, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489eee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = z_cs.view(z_cs.shape[0], -1).cpu().numpy()\n",
    "y_content = labels.cpu().numpy()\n",
    "y_style = styles.cpu().numpy()\n",
    "\n",
    "\n",
    "N = X.shape[0]\n",
    "N_sub = 10000   \n",
    "idx = np.random.choice(N, size=min(N_sub, N), replace=False)\n",
    "\n",
    "X_sub = X[idx]\n",
    "content_sub = y_content[idx]\n",
    "style_sub = y_style[idx]\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    init='pca',\n",
    "    perplexity=100,\n",
    "    learning_rate=800,\n",
    "    max_iter=8000,\n",
    "    early_exaggeration=40,\n",
    "    random_state=0,\n",
    ")\n",
    "z_2d = tsne.fit_transform(X_sub)  \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs0 = axs[0].scatter(\n",
    "    z_2d[:, 0],\n",
    "    z_2d[:, 1],\n",
    "    c=content_sub,        \n",
    "    cmap='tab10',\n",
    "    alpha=0.4,\n",
    "    s=5,\n",
    ")\n",
    "cbar = fig.colorbar(axs0, ax=axs[0])\n",
    "axs[0].set_title('color by content (5 types)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1bed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = z_ss.view(z_ss.shape[0], -1).cpu().numpy()\n",
    "y_content = labels.cpu().numpy()\n",
    "y_style = styles.cpu().numpy()\n",
    "\n",
    "N = X.shape[0]\n",
    "N_sub = 10000   \n",
    "idx = np.random.choice(N, size=min(N_sub, N), replace=False)\n",
    "\n",
    "X_sub = X[idx]\n",
    "content_sub = y_content[idx]\n",
    "style_sub = y_style[idx]\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    init='pca',\n",
    "    perplexity=100,\n",
    "    learning_rate=800,\n",
    "    max_iter=8000,\n",
    "    early_exaggeration=40,\n",
    "    random_state=0,\n",
    ")\n",
    "z_2d = tsne.fit_transform(X_sub)   \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs0 = axs[0].scatter(\n",
    "    z_2d[:, 0],\n",
    "    z_2d[:, 1],\n",
    "    c=content_sub,       \n",
    "    cmap='tab10',\n",
    "    alpha=0.4,\n",
    "    s=5,\n",
    ")\n",
    "cbar = fig.colorbar(axs0, ax=axs[0])\n",
    "axs[0].set_title('color by content (5 types)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229ad04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
